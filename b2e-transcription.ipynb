{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility for context-aware removal of ZWNJ and ZWJ in Bangla text.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import io\n",
    "import re\n",
    "\n",
    "\n",
    "STANDARDIZE_ZW = re.compile(r'(?<=\\u09b0)[\\u200c\\u200d]+(?=\\u09cd\\u09af)')\n",
    "DELETE_ZW = re.compile(r'(?<!\\u09b0)[\\u200c\\u200d](?!\\u09cd\\u09af)')\n",
    "\n",
    "\n",
    "def RemoveOptionalZW(text):\n",
    "    text = STANDARDIZE_ZW.sub('\\u200D', text)\n",
    "    text = DELETE_ZW.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words in google lexicon: 64970\n"
     ]
    }
   ],
   "source": [
    "googlex = {} # dictionary containing google lexicon\n",
    "\n",
    "with open('lexicon.tsv') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#'): \n",
    "            continue\n",
    "            \n",
    "        items = line.strip().split('\\t')\n",
    "        if len(items) >= 2:\n",
    "            word, pron = items[0], items[1]\n",
    "            \n",
    "            # duplicate check\n",
    "            #if word in googlex:\n",
    "            #    print(word, '\\t', pron, '\\t', googlex[word])\n",
    "            googlex[word] = pron\n",
    "            \n",
    "print('total words in google lexicon:', len(googlex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words in sust lexicon: 135760\n"
     ]
    }
   ],
   "source": [
    "sustlex = {} # dictionary containing sust lexicon\n",
    "\n",
    "with open('bn_lexicon_final_sorted.txt') as f:\n",
    "    for line in f:\n",
    "        items = line.strip().split()\n",
    "        \n",
    "        # error check\n",
    "        if len(items) != 2:\n",
    "            print(items)\n",
    "            continue\n",
    "            \n",
    "        word, pron = items[0], items[1]\n",
    "        sustlex[word] = pron\n",
    "\n",
    "print('total words in sust lexicon:', len(sustlex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total transcription rules: 56\n"
     ]
    }
   ],
   "source": [
    "trans = {} # dictionary containing the transcription map\n",
    "\n",
    "with open('conversion_map.txt') as f:\n",
    "    for line in f:\n",
    "        items = line.strip().split()\n",
    "        if len(items) >= 2:\n",
    "            trans[ RemoveOptionalZW(items[0]) ] = ' '.join(items[1:])\n",
    "            \n",
    "print('total transcription rules:', len(trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Issues to handle:\n",
    "\n",
    "** implicit O. Ex- ক -> k O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(word):\n",
    "    result = []\n",
    "    i = 0\n",
    "    wlen = len(word)\n",
    "    prev1 = prev2 = ''\n",
    "    \n",
    "    while i < wlen:\n",
    "        if word[i:].startswith('\\u09cd\\u09af\\u09be'): # ্যা্যা\n",
    "            result.append('E')\n",
    "            i += 3\n",
    "            continue\n",
    "        \n",
    "        c = word[i]\n",
    "        if c in trans:\n",
    "            if c=='\\u09cd' and i==wlen-1:\n",
    "                pass\n",
    "            else:\n",
    "                result.append(trans[c])\n",
    "            \n",
    "        i += 1\n",
    "            \n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['প', 'া', 'ক', 'স', '্', 'থ', 'ল', 'ি', 'র', '্']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'পাকস্থলির্'\n",
    "list(word)\n",
    "# transcribe(word)\n",
    "# trans['\\u09cd']\n",
    "#trans.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sustlex = random.sample(sustlex.items(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ক্যাম্পাস \t ক্যাম্পাস্ \t k E m . p a s \t k E m . p a s\n",
      "থামলেন \t থাম্লেন্ \t th a m . l e n \t th a m . l e n\n",
      "পাকস্থলীর \t পাকস্থলির্ \t p a . k o s . th o . l i r \t p a k s . th l i r\n",
      "আওতা \t আও্তা \t a o^ . t a \t a o . t a\n",
      "ক্যাভিটি \t ক্যাভিটি \t k E . bh i . T i \t k E bh i T i\n"
     ]
    }
   ],
   "source": [
    "for k, v in sample_sustlex:\n",
    "    if k in googlex:\n",
    "        result = transcribe(v)\n",
    "        print(k, '\\t', v, '\\t', googlex[k], '\\t', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=b=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
